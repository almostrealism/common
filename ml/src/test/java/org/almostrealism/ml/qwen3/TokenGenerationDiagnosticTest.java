package org.almostrealism.ml.qwen3;

import org.almostrealism.collect.PackedCollection;
import org.almostrealism.io.Console;
import org.almostrealism.io.ConsoleFeatures;
import org.almostrealism.io.OutputFeatures;
import org.almostrealism.ml.AutoregressiveModel;
import org.almostrealism.ml.StateDictionary;
import org.junit.Test;

import java.util.ArrayList;
import java.util.List;

/**
 * Diagnostic test to observe actual token IDs generated by Qwen3.
 *
 * <p>This test aims to understand why Qwen3 produces garbage output
 * by examining the raw token IDs at each generation step.</p>
 */
public class TokenGenerationDiagnosticTest implements ConsoleFeatures {
    private static final String WEIGHTS_DIR = "/workspace/project/common/ml/qwen3_weights";
    private static final String TOKENIZER_PATH = WEIGHTS_DIR + "/tokenizer.bin";

    /**
     * Observe token generation step by step with detailed logging.
     */
    @Test
    public void testTokenGenerationStepByStep() throws Exception {
        String logFile = "/workspace/project/common/ml/test_output/token_generation_debug.txt";
        Console.root().addListener(OutputFeatures.fileOutput(logFile));

        log("\n" + "=".repeat(70));
        log("TOKEN GENERATION DIAGNOSTIC TEST");
        log("=".repeat(70) + "\n");

        // Load model with small sequence length for debugging
        Qwen3Config config = new Qwen3Config(
            896, 4864, 24, 14, 2, 151936, 32768, true, 1000000.0
        );

        StateDictionary stateDict = new StateDictionary(WEIGHTS_DIR);
        Qwen3Tokenizer tokenizer = new Qwen3Tokenizer(TOKENIZER_PATH);
        Qwen3 model = new Qwen3(config, stateDict, tokenizer);

        log("[Model loaded successfully]");
        log("Vocabulary size: " + config.vocabSize);
        log("BOS token: " + Qwen3Tokenizer.BOS_TOKEN);
        log("EOS token: " + Qwen3Tokenizer.EOS_TOKEN);

        String prompt = "Hello";
        log("\n" + "-".repeat(70));
        log("PROMPT: \"" + prompt + "\"");
        log("-".repeat(70));

        // Encode prompt
        int[] promptTokens = tokenizer.encode(prompt, true, false);
        log("Encoded prompt tokens (" + promptTokens.length + " tokens):");
        for (int i = 0; i < promptTokens.length; i++) {
            String decoded = tokenizer.decode(new int[]{promptTokens[i]});
            log(String.format("  [%d] token=%d -> \"%s\"", i, promptTokens[i], decoded));
        }

        // Set up for generation
        AutoregressiveModel arm = model.getAutoregressiveModel();
        arm.setTemperature(0.0);  // Greedy for reproducibility
        arm.setCurrentToken(Qwen3Tokenizer.BOS_TOKEN);
        arm.setPrompt(promptTokens, promptTokens.length);
        arm.setCurrentStep(0);  // Reset step counter

        log("\n--- Generation Steps ---");
        log("Using temperature=0.0 (greedy decoding)");

        List<Integer> generatedTokens = new ArrayList<>();
        int maxSteps = promptTokens.length + 10;  // Generate 10 tokens beyond prompt

        for (int step = 0; step < maxSteps; step++) {
            int nextToken = arm.next();
            generatedTokens.add(nextToken);

            String decoded = tokenizer.decode(new int[]{nextToken});
            String phase = step < promptTokens.length ? "[PROMPT]" : "[GENERATED]";
            log(String.format("Step %2d: %s token=%6d -> \"%s\" (0x%04X)",
                step, phase, nextToken, decoded, nextToken));

            // Check for anomalies
            if (nextToken < 0 || nextToken >= config.vocabSize) {
                log("  WARNING: Token ID out of vocabulary range!");
            }

            if (nextToken == Qwen3Tokenizer.EOS_TOKEN) {
                log("  [EOS reached]");
                break;
            }
        }

        // Analyze generated tokens
        log("\n--- Analysis ---");

        // Check for repetition
        int repeatCount = 0;
        int lastToken = -1;
        int longestRepeat = 0;
        int currentRepeat = 0;

        for (int i = promptTokens.length; i < generatedTokens.size(); i++) {
            int token = generatedTokens.get(i);
            if (token == lastToken) {
                currentRepeat++;
                repeatCount++;
            } else {
                if (currentRepeat > longestRepeat) {
                    longestRepeat = currentRepeat;
                }
                currentRepeat = 1;
            }
            lastToken = token;
        }
        if (currentRepeat > longestRepeat) {
            longestRepeat = currentRepeat;
        }

        log(String.format("Longest token repetition: %d times", longestRepeat));

        // Decode full output
        int[] genTokensArray = generatedTokens.stream().mapToInt(i -> i).toArray();
        String fullOutput = tokenizer.decode(genTokensArray);
        log("\nFull output: \"" + fullOutput + "\"");

        // Decode just the generated part (excluding prompt)
        if (generatedTokens.size() > promptTokens.length) {
            int[] genOnly = new int[generatedTokens.size() - promptTokens.length];
            for (int i = 0; i < genOnly.length; i++) {
                genOnly[i] = generatedTokens.get(promptTokens.length + i);
            }
            String generatedOnly = tokenizer.decode(genOnly);
            log("Generated (excluding prompt): \"" + generatedOnly + "\"");
        }

        stateDict.destroy();

        log("\n" + "=".repeat(70));
        log("TEST COMPLETE");
        log("=".repeat(70));
    }

    /**
     * Test raw logits output to verify model is producing reasonable values.
     */
    @Test
    public void testLogitsOutput() throws Exception {
        String logFile = "/workspace/project/common/ml/test_output/logits_debug.txt";
        Console.root().addListener(OutputFeatures.fileOutput(logFile));

        log("\n" + "=".repeat(70));
        log("LOGITS OUTPUT DIAGNOSTIC TEST");
        log("=".repeat(70) + "\n");

        // Load model
        Qwen3Config config = new Qwen3Config(
            896, 4864, 24, 14, 2, 151936, 32768, true, 1000000.0
        );

        StateDictionary stateDict = new StateDictionary(WEIGHTS_DIR);
        Qwen3Tokenizer tokenizer = new Qwen3Tokenizer(TOKENIZER_PATH);
        Qwen3 model = new Qwen3(config, stateDict, tokenizer);

        log("[Model loaded]");

        // Get compiled model for direct logits access
        org.almostrealism.model.CompiledModel compiledModel = model.getCompiledModel();
        PackedCollection tokenEmbeddings = model.getTokenEmbeddings();

        log("Input shape: " + compiledModel.getInputShape());
        log("Output shape: " + compiledModel.getOutputShape());

        // Test with BOS token at position 0
        log("\n--- Forward pass with BOS token at position 0 ---");

        PackedCollection input = new PackedCollection(compiledModel.getInputShape());
        int bosToken = Qwen3Tokenizer.BOS_TOKEN;

        // Copy BOS embedding to input
        int dim = config.dim;
        for (int i = 0; i < dim; i++) {
            input.setMem(i, tokenEmbeddings.toDouble(bosToken * dim + i));
        }

        // Run forward pass
        PackedCollection logits = compiledModel.forward(input);

        // Analyze logits
        double minLogit = Double.MAX_VALUE;
        double maxLogit = Double.MIN_VALUE;
        double sum = 0;
        int nanCount = 0;
        int infCount = 0;

        for (int i = 0; i < config.vocabSize; i++) {
            double v = logits.toDouble(i);
            if (Double.isNaN(v)) {
                nanCount++;
            } else if (Double.isInfinite(v)) {
                infCount++;
            } else {
                if (v < minLogit) minLogit = v;
                if (v > maxLogit) maxLogit = v;
                sum += v;
            }
        }

        log(String.format("Logits: min=%.4f, max=%.4f, mean=%.4f",
            minLogit, maxLogit, sum / config.vocabSize));
        log(String.format("NaN count: %d, Inf count: %d", nanCount, infCount));

        // Find top 5 predictions
        log("\nTop 5 predictions:");
        for (int rank = 0; rank < 5; rank++) {
            int maxIdx = -1;
            double maxVal = Double.NEGATIVE_INFINITY;
            for (int i = 0; i < config.vocabSize; i++) {
                double v = logits.toDouble(i);
                if (!Double.isNaN(v) && !Double.isInfinite(v) && v > maxVal) {
                    // Check if already used in higher rank
                    boolean used = false;
                    for (int j = 0; j < rank; j++) {
                        // Simple check - would need to track previous winners
                    }
                    if (!used) {
                        maxVal = v;
                        maxIdx = i;
                    }
                }
            }
            if (maxIdx >= 0) {
                // Set to negative infinity so we don't pick it again
                logits.setMem(maxIdx, Double.NEGATIVE_INFINITY);
                String decoded = tokenizer.decode(new int[]{maxIdx});
                log(String.format("  #%d: token=%d (%.4f) -> \"%s\"",
                    rank + 1, maxIdx, maxVal, decoded));
            }
        }

        stateDict.destroy();

        log("\n" + "=".repeat(70));
        log("TEST COMPLETE");
        log("=".repeat(70));
    }
}
